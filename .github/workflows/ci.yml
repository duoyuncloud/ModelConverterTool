name: CI

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  lint-and-test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.11]

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - name: Upgrade pip and install build tools
        run: |
          python -m pip install --upgrade pip setuptools wheel

      - name: Install core dependencies
        run: |
          pip install torch>=2.0.0 transformers>=4.30.0 tokenizers>=0.13.0 accelerate>=0.20.0

      - name: Install remaining dependencies
        run: |
          pip install -r requirements.txt

      - name: Install quantization libraries (optional)
        run: |
          pip install datasets>=2.0.0 || echo "datasets installation failed, continuing..."
          pip install logbar || echo "logbar installation failed, continuing..."
          pip install gptqmodel>=0.1.0 || echo "gptqmodel installation failed, continuing..."

      - name: Install dev tools and editable package
        run: |
          pip install flake8 black isort
          pip install -e .

      - name: Lint with isort/black/flake8
        run: |
          isort --check-only --diff model_converter_tool/ --profile black
          black --check model_converter_tool/
          flake8 model_converter_tool/ --count --select=E9,F63,F7,F82 --show-source --statistics

      - name: Run fast CI tests
        run: python ci_fast_test.py

      - name: Run slow CI tests
        run: python ci_slow_test.py

      - name: Run all tests
        run: python test_all.py

  test:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest]
        python-version: ['3.11']
        exclude:
          - os: macos-latest
            python-version: '3.9'

    timeout-minutes: 30

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}


    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ matrix.python-version }}-v2-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-${{ matrix.python-version }}-v2-
          ${{ runner.os }}-pip-${{ matrix.python-version }}-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip setuptools wheel
        pip cache purge || echo "Cache purge failed, continuing..."
        pip install -r requirements.txt
        # Install quantization libraries separately after torch is installed
        pip install datasets>=2.0.0 || echo "datasets installation failed, continuing..."
        pip install logbar || echo "logbar installation failed, continuing..."
        pip install gptqmodel>=0.1.0 || echo "gptqmodel installation failed, continuing..."

    - name: Test package installation
      run: |
        pip install -e .
        python -c "from model_converter_tool.converter import ModelConverter; print('✅ Package installed successfully')"

    - name: Test CLI help
      run: |
        model-converter --help

    - name: Test fast conversions
      run: |
        python ci_fast_test.py

    - name: Test slow conversions (quantization)
      run: |
        python ci_slow_test.py

    - name: Test batch conversion
      run: |
        python -c "
        from model_converter_tool.converter import ModelConverter
        converter = ModelConverter()
        
        tasks = [
            {
                'input_source': 'gpt2',
                'output_format': 'hf',
                'output_path': 'outputs/batch_test_gpt2_hf',
                'model_type': 'text-generation',
                'device': 'cpu'
            },
            {
                'input_source': 'gpt2',
                'output_format': 'onnx',
                'output_path': 'outputs/batch_test_gpt2_onnx',
                'model_type': 'text-generation',
                'device': 'cpu'
            }
        ]
        
        results = converter.batch_convert(tasks, max_workers=2)
        success_count = sum(1 for r in results if r.get('success'))
        print(f'✅ Batch conversion: {success_count}/{len(results)} successful')
        "

    - name: Upload test artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-outputs-${{ matrix.os }}-${{ matrix.python-version }}
        path: outputs/
        retention-days: 1

  integration:
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip setuptools wheel
        pip install -r requirements.txt

    - name: Test integration scenarios
      run: |
        python -c "
        from model_converter_tool.converter import ModelConverter
        import os
        
        converter = ModelConverter()
        
        # Test supported formats
        formats = converter.get_supported_formats()
        print(f'✅ Supported formats: {list(formats.keys())}')
        
        # Test conversion info
        info = converter.get_conversion_info('gpt2', 'hf')
        print(f'✅ Conversion info: {info.get(\"supported\", False)}')
        
        # Test validation
        valid = converter.validate_conversion('gpt2', 'hf')
        print(f'✅ Validation: {valid}')
        
        # Test model size estimation
        size = converter._estimate_model_size('gpt2')
        print(f'✅ Model size estimation: {size:.2f} MB')
        "

    - name: Test error handling
      run: |
        python -c "
        from model_converter_tool.converter import ModelConverter
        
        converter = ModelConverter()
        
        # Test invalid model
        result = converter.convert(
            input_source='invalid-model-name',
            output_format='hf',
            output_path='outputs/invalid_test',
            model_type='text-generation',
            device='cpu'
        )
        print(f'✅ Error handling: {not result.get(\"success\", True)}')
        "

  security:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install security tools
      run: |
        python -m pip install --upgrade pip
        pip install bandit safety

    - name: Run security scan
      run: |
        bandit -r model_converter_tool/ -f json -o bandit-report.json || true
        safety check --json --output safety-report.json || true

    - name: Upload security reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json
        retention-days: 7

  critical-test:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip setuptools wheel
        pip cache purge || echo "Cache purge failed, continuing..."
        pip install -r requirements.txt
        # Install quantization libraries separately after torch is installed
        pip install datasets>=2.0.0 || echo "datasets installation failed, continuing..."
        pip install logbar || echo "logbar installation failed, continuing..."
        pip install gptqmodel>=0.1.0 || echo "gptqmodel installation failed, continuing..."

    - name: Test critical functionality
      run: |
        pip install -e .
        python -c "from model_converter_tool.converter import ModelConverter; print('✅ Package installed successfully')"
        python ci_fast_test.py

  quantization-test:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -r requirements.txt
          pip install datasets logbar gptqmodel device_smi tokenicer threadpoolctl

      - name: Run quantization-only tests
        run: |
          python ci_slow_test.py

      - name: Show Python version and environment
        run: |
          python --version
          which python
          echo $PATH

      - name: List installed pip packages
        run: |
          pip list

      - name: Check pip dependency health
        run: |
          pip check

      - name: Check quantization dependencies
        run: |
          python check_quant_deps.py || true 