# Batch conversion configuration template (matches README demo)
# Edit this file and run with batch_convert_from_yaml

models:
  bert_to_onnx:
    input: "bert-base-uncased"
    output_format: "onnx"
    output_path: "outputs/bert.onnx"
    model_type: "feature-extraction"
    device: "cpu"
  tiny_gpt2_to_fp16:
    input: "sshleifer/tiny-gpt2"
    output_format: "fp16"
    output_path: "outputs/tiny_gpt2_fp16"
    model_type: "text-generation"
    device: "cpu"
  gpt2_to_torchscript:
    input: "gpt2"
    output_format: "torchscript"
    output_path: "outputs/gpt2.pt"
    model_type: "text-generation"
    device: "cpu"