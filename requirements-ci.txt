# CI-specific requirements (excludes GPU-specific and problematic dependencies)
# Core dependencies
torch>=2.0.0
transformers>=4.30.0
tokenizers>=0.13.0
accelerate>=0.20.0

# Model conversion libraries
onnx>=1.14.0
onnxruntime>=1.15.0

# Configuration and utilities
pyyaml>=6.0
click>=8.0.0
rich>=13.0.0
tqdm>=4.65.0
sentencepiece>=0.1.99
protobuf>=3.20.0
requests>=2.25.0

# Development dependencies
pytest>=7.0.0
pytest-cov>=4.0.0
pytest-timeout>=2.0.0
black>=23.0.0
flake8>=6.0.0

# Excluded from CI (GPU-specific or problematic):
# - auto-gptq>=0.4.0 (CUDA only)
# - autoawq>=0.2.0 (CUDA only)
# - llama-cpp-python>=0.2.0 (optional)
# - mlx>=0.0.8 (Apple Silicon only)

# Added from the code block (commented out for CI)
# auto-gptq  # CUDA only, excluded from CI
# llama-cpp-python  # Optional, excluded from CI
tiktoken>=0.5.0 