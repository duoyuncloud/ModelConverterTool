# NOTE: For proper installation, use install_dependencies.sh or install requirements-core.txt first, then requirements-optional.txt
# Core dependencies
torch>=2.0.0
transformers>=4.30.0
tokenizers>=0.13.0
accelerate>=0.20.0

# Model conversion libraries
onnx>=1.14.0
onnxruntime>=1.15.0

# Optional: GGUF conversion
llama-cpp-python>=0.2.0

# Optional: MLX for Apple Silicon
mlx>=0.0.8

# Quantization libraries (install after torch)
# These are optional and may fail if torch is not properly installed
# gptqmodel  # 主要量化转换库，需在torch安装后单独pip install
logbar
tokenicer
device_smi
threadpoolctl
Pillow
safetensors

# Configuration and utilities
pyyaml>=6.0
click>=8.0.0
rich>=13.0.0
tqdm>=4.65.0

# Optional: For better performance
sentencepiece>=0.1.99
protobuf>=3.20.0
datasets>=2.0.0  # Required for quantization libraries

# Development dependencies
pytest>=7.0.0
black>=23.0.0
flake8>=6.0.0

# autoawq>=0.2.0    # 已弃用，使用 gptqmodel 替代

# Optional dependencies for advanced features/postprocess:
# onnxsim: ONNX model simplification (for postprocess:simplify)
# torch-optimizer: TorchScript optimization (for postprocess:optimize)
# safetensors: Fast model saving/loading (already required)
# To install all optional features:
# pip install onnxsim torch-optimizer

# Optional/advanced quantization dependencies
# auto-gptq
optimum
peft
# triton  # OpenAI Triton，仅限部分Linux+Python3.8~3.10环境需要
lm-eval
evalplus
intel-extension-for-pytorch
bitblas

# For testing
pytest>=7.0.0 