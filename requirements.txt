# Core dependencies
torch>=2.0.0
transformers>=4.30.0
tokenizers>=0.13.0
accelerate>=0.20.0

# Model conversion
onnx>=1.14.0
onnxruntime>=1.15.0
optimum>=1.8.0

# Quantization (install after torch)
gptqmodel
logbar
tokenicer
device_smi
threadpoolctl
Pillow
safetensors

# Configuration and utilities
pyyaml>=6.0
rich>=13.0.0
tqdm>=4.65.0
typer>=0.16.0

# Optional: Performance and dataset support
sentencepiece>=0.1.99
protobuf>=3.20.0
datasets>=2.0.0

# Development and testing
pytest>=7.0.0
black>=23.0.0
flake8>=6.0.0

# Optional/advanced quantization
peft
lm-eval
evalplus
random_word>=1.0.8
numpy
llama-cpp-python  # GGUF inference and checks
mlx-lm  # MLX conversion and inference
tiktoken 