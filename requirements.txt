# NOTE: For proper installation, use install_dependencies.sh or install requirements-core.txt first, then requirements-optional.txt
# Core dependencies
torch>=2.0.0
transformers>=4.30.0
tokenizers>=0.13.0
accelerate>=0.20.0

# Model conversion libraries
onnx>=1.14.0
onnxruntime>=1.15.0

# Optional: GGUF conversion
llama-cpp-python>=0.2.0

# Optional: MLX for Apple Silicon
mlx>=0.0.8

# Quantization libraries (install after torch)
# These are optional and may fail if torch is not properly installed
# gptqmodel>=0.1.0  # 主要量化转换库 - 暂时注释掉，在CI中单独处理
# auto-gptq>=0.4.0  # 可选，仅用于验证已转换的模型 - 暂时注释掉，在CI中单独处理

# Configuration and utilities
pyyaml>=6.0
click>=8.0.0
rich>=13.0.0
tqdm>=4.65.0

# Optional: For better performance
sentencepiece>=0.1.99
protobuf>=3.20.0
datasets>=2.0.0  # Required for quantization libraries
safetensors>=0.3.0  # Fast model saving/loading

# Development dependencies
pytest>=7.0.0
black>=23.0.0
flake8>=6.0.0

# autoawq>=0.2.0    # 已弃用，使用 gptqmodel 替代

# Optional dependencies for advanced features/postprocess:
# onnxsim: ONNX model simplification (for postprocess:simplify)
# torch-optimizer: TorchScript optimization (for postprocess:optimize)
# safetensors: Fast model saving/loading (already required)
# To install all optional features:
# pip install onnxsim torch-optimizer

# For testing
pytest>=7.0.0

logbar  # Required for quantization libraries 